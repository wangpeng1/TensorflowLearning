{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorflow-tutorial/blob/master/lab1_FFN/lab1_FFN.ipynb\n",
    "# 各种函数\n",
    "\n",
    "# y_ is a placeholder variable taking on the value of the target batch.\n",
    "y_ = tf.placeholder(tf.float32, [None, num_output])\n",
    "\n",
    "# computing cross entropy per sample\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1])\n",
    "\n",
    "# averaging over samples\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "## 优化函数替代\n",
    "# Defining our optimizer (try with different optimizers here!)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "\n",
    "# Computing our gradients\n",
    "grads_and_vars = optimizer.compute_gradients(cross_entropy)\n",
    "\n",
    "# Applying the gradients\n",
    "train_op = optimizer.apply_gradients(grads_and_vars)\n",
    "\n",
    "# Notice, alternatively you can use train_op = optimizer.minimize(crossentropy)\n",
    "# instead of the three steps above\n",
    "\n",
    "# making a one-hot encoded vector of correct (1) and incorrect (0) predictions\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "\n",
    "# averaging the one-hot encoded vector\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# restricting memory usage, TensorFlow is greedy and will use all memory otherwise\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.2)\n",
    "# initialize the Session\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "res = sess.run(fetches=[y], feed_dict={x_pl: x})\n",
    "print \"y\", res[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Single GPU computing\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant(A)\n",
    "    b = tf.constant(B)\n",
    "    #compute A^n and B^n and store results in c1\n",
    "    c1.append(matpow(a, n))\n",
    "    c1.append(matpow(b, n))\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "  sum = tf.add_n(c1) #Addition of all elements in c1, i.e. A^n + B^n\n",
    "\n",
    "t1_1 = datetime.datetime.now()\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=log_device_placement)) as sess:\n",
    "    # Runs the op.\n",
    "    sess.run(sum)\n",
    "t2_1 = datetime.datetime.now()\n",
    "\n",
    "# Multi GPU computing\n",
    "# GPU:0 computes A^n\n",
    "with tf.device('/gpu:0'):\n",
    "    #compute A^n and store result in c2\n",
    "    a = tf.constant(A)\n",
    "    c2.append(matpow(a, n))\n",
    "\n",
    "#GPU:1 computes B^n\n",
    "with tf.device('/gpu:1'):\n",
    "    #compute B^n and store result in c2\n",
    "    b = tf.constant(B)\n",
    "    c2.append(matpow(b, n))\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "  sum = tf.add_n(c2) #Addition of all elements in c2, i.e. A^n + B^n\n",
    "\n",
    "t1_2 = datetime.datetime.now()\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=log_device_placement)) as sess:\n",
    "    # Runs the op.\n",
    "    sess.run(sum)\n",
    "t2_2 = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/floydhub/tensorflow-notebooks-examples/blob/master/3_NeuralNetworks/autoencoder.ipynb\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 20\n",
    "batch_size = 256\n",
    "display_step = 1\n",
    "examples_to_show = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer num features\n",
    "n_hidden_2 = 128 # 2nd layer num features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "\n",
    "# tf Graph input (only pictures)\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'encoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])),\n",
    "    'decoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_input])),\n",
    "}\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'encoder_b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'decoder_b2': tf.Variable(tf.random_normal([n_input])),\n",
    "}\n",
    "\n",
    "# Building the encoder\n",
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
    "                                   biases['encoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
    "                                   biases['encoder_b2']))\n",
    "    return layer_2\n",
    "\n",
    "\n",
    "# Building the decoder\n",
    "def decoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),\n",
    "                                   biases['decoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']),\n",
    "                                   biases['decoder_b2']))\n",
    "    return layer_2\n",
    "\n",
    "# Construct model\n",
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "\n",
    "# Prediction\n",
    "y_pred = decoder_op\n",
    "# Targets (Labels) are the input data.\n",
    "y_true = X\n",
    "\n",
    "# Define loss and optimizer, minimize the squared error\n",
    "cost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "# Using InteractiveSession (more convenient while using Notebooks)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={X: batch_xs})\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1),\n",
    "              \"cost=\", \"{:.9f}\".format(c))\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "# Applying encode and decode over test set\n",
    "encode_decode = sess.run(\n",
    "    y_pred, feed_dict={X: mnist.test.images[:examples_to_show]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分布式 https://github.com/Hezi-Resheff/Oreilly-Learning-TensorFlow/blob/master/09__distributed_tensorflow/distribute.py\n",
    "# tf.nn.softmax_cross_entropy_with_logits(y, y_)\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import slim\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "TRAINING_STEPS = 5000\n",
    "PRINT_EVERY = 100\n",
    "LOG_DIR = \"/tmp/log\"\n",
    "\n",
    "\n",
    "parameter_servers = [\"localhost:2222\"]\n",
    "workers = [\"localhost:2223\",\n",
    "           \"localhost:2224\",\n",
    "           \"localhost:2225\"]\n",
    "\n",
    "cluster = tf.train.ClusterSpec({\"ps\": parameter_servers, \"worker\": workers})\n",
    "\n",
    "\n",
    "tf.app.flags.DEFINE_string(\"job_name\", \"\", \"'ps' / 'worker'\")\n",
    "tf.app.flags.DEFINE_integer(\"task_index\", 0, \"Index of task\")\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "\n",
    "server = tf.train.Server(cluster,\n",
    "                         job_name=FLAGS.job_name,\n",
    "                         task_index=FLAGS.task_index)\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "\n",
    "def net(x):\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    net = slim.layers.conv2d(x_image, 32, [5, 5], scope='conv1')\n",
    "    net = slim.layers.max_pool2d(net, [2, 2], scope='pool1')\n",
    "    net = slim.layers.conv2d(net, 64, [5, 5], scope='conv2')\n",
    "    net = slim.layers.max_pool2d(net, [2, 2], scope='pool2')\n",
    "    net = slim.layers.flatten(net, scope='flatten')\n",
    "    net = slim.layers.fully_connected(net, 500, scope='fully_connected')\n",
    "    net = slim.layers.fully_connected(net, 10, activation_fn=None, scope='pred')\n",
    "    return net\n",
    "\n",
    "\n",
    "if FLAGS.job_name == \"ps\":\n",
    "    server.join()\n",
    "\n",
    "elif FLAGS.job_name == \"worker\":\n",
    "\n",
    "    with tf.device(tf.train.replica_device_setter(\n",
    "            worker_device=\"/job:worker/task:%d\" % FLAGS.task_index,\n",
    "            cluster=cluster)):\n",
    "\n",
    "        global_step = tf.get_variable('global_step', [],\n",
    "                                      initializer=tf.constant_initializer(0),\n",
    "                                      trainable=False)\n",
    "\n",
    "        x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x-input\")\n",
    "        y_ = tf.placeholder(tf.float32, shape=[None, 10], name=\"y-input\")\n",
    "        y = net(x)\n",
    "\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy,\n",
    "                                                           global_step=global_step)\n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        init_op = tf.global_variables_initializer()\n",
    "\n",
    "    sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),\n",
    "                             logdir=LOG_DIR,\n",
    "                             global_step=global_step,\n",
    "                             init_op=init_op)\n",
    "\n",
    "    with sv.managed_session(server.target) as sess:\n",
    "        step = 0\n",
    "\n",
    "        while not sv.should_stop() and step <= TRAINING_STEPS:\n",
    "\n",
    "            batch_x, batch_y = mnist.train.next_batch(BATCH_SIZE)\n",
    "\n",
    "            _, acc, step = sess.run([train_step, accuracy, global_step],\n",
    "                                    feed_dict={x: batch_x, y_: batch_y})\n",
    "\n",
    "            if step % PRINT_EVERY == 0:\n",
    "                print(\"Worker : {}, Step: {}, Accuracy (batch): {}\".\n",
    "                      format(FLAGS.task_index, step, acc))\n",
    "\n",
    "        test_acc = sess.run(accuracy,\n",
    "                            feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "        print(\"Test-Accuracy: {}\".format(test_acc))\n",
    "\n",
    "    sv.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 运行上面的\n",
    "import subprocess\n",
    "subprocess.Popen('python distribute.py --job_name=\"ps\" --task_index=0',\n",
    "                 shell=True)\n",
    "subprocess.Popen('python distribute.py --job_name=\"worker\" --task_index=0',\n",
    "                 shell=True)\n",
    "subprocess.Popen('python distribute.py --job_name=\"worker\" --task_index=1',\n",
    "                 shell=True)\n",
    "subprocess.Popen('python distribute.py --job_name=\"worker\" --task_index=2',\n",
    "                 shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 区别\n",
    "#tf.nn.softmax_cross_entropy_with_logits \n",
    "\n",
    "y_hat_softmax = tf.nn.softmax(y_hat)\n",
    "total_loss = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(y_hat_softmax), [1]))\n",
    "\n",
    "total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true))\n",
    "\n",
    "tf.nn.softmax_cross_entropy_with_logits(logits, labels, name=None)\n",
    "除去name参数用以指定该操作的name，与方法有关的一共两个参数：\n",
    "第一个参数logits：就是神经网络最后一层的输出，如果有batch的话，它的大小就是[batchsize，num_classes]，单样本的话，大小就是num_classes\n",
    "第二个参数labels：实际的标签，大小同上\n",
    "\n",
    "sigmoid_cross_entropy_with_logits详解注意不需要经过sigmoid，而targets的shape和logits相同，就是正确的label值，\n",
    "例如这个模型一次要判断100张图是否包含10种动物，这两个输入的shape都是[100, 10]。\n",
    "注释中还提到这10个分类之间是独立的、不要求是互斥，这种问题我们成为多目标\n",
    "，例如判断图片中是否包含10种动物，label值可以包含多个1或0个1，\n",
    "还有一种问题是多分类问题，例如我们对年龄特征分为5段，只允许5个值有且只有1个值为1，这种问题可以直接用这个函数吗？答案是不可以\n",
    "\n",
    "softmax_cross_entropy_with_logits详解oftmax本身的算法很简单，就是把所有值用e的n次方计算出来，求和后算每个值占的比率，保证总和为1，\n",
    "一般我们可以认为Softmax出来的就是confidence但这里要求分类的结果是互斥的，保证只有一个字段有值\n",
    "因此这个函数只适合单目标的二分类或者多分类问题\n",
    "\n",
    "sparse_softmax_cross_entropy_with_logits详解是softmax_cross_entropy_with_logits的易用版本，除了输入参数不同，作用和算法实现都是一样的。\n",
    "如果用户已经做了onehot encoding那可以直接使用不带“sparse”的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 使用已有的分类 建立网络图片和web 使用\n",
    "## 更新已有的分类\n",
    "# https://deeplearningsandbox.com/how-to-build-an-image-recognition-system-using-keras-and-tensorflow-for-a-1000-everyday-object-559856e04699\n",
    "# https://deeplearningsandbox.com/how-to-use-transfer-learning-and-fine-tuning-in-keras-and-tensorflow-to-build-an-image-recognition-94b0b02444f2\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "target_size = (224, 224)\n",
    "\n",
    "def predict(model, img, target_size, top_n=3):\n",
    "  \"\"\"Run model prediction on image\n",
    "  Args:\n",
    "    model: keras model\n",
    "    img: PIL format image\n",
    "    target_size: (w,h) tuple\n",
    "    top_n: # of top predictions to return\n",
    "  Returns:\n",
    "    list of predicted labels and their probabilities\n",
    "  \"\"\"\n",
    "    if img.size != target_size:\n",
    "        img = img.resize(target_size)\n",
    "\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "\n",
    "return decode_predictions(preds, top=top_n)[0]\n",
    "\n",
    "def plot_preds(image, preds):\n",
    "    \n",
    "\"\"\"Displays image and the top-n predicted probabilities in a bar graph\n",
    "Args:\n",
    "image: PIL image\n",
    "preds: list of predicted labels and their probabilities\n",
    "\"\"\"\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.figure()\n",
    "    order = list(reversed(range(len(preds))))\n",
    "    bar_preds = [pr[2] for pr in preds]\n",
    "    labels = (pr[1] for pr in preds)\n",
    "    plt.barh(order, bar_preds, alpha=0.5)\n",
    "    plt.yticks(order, labels)\n",
    "    plt.xlabel('Probability')\n",
    "    plt.xlim(0,1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    a = argparse.ArgumentParser()\n",
    "    a.add_argument(\"--image\", help=\"path to image\")\n",
    "    a.add_argument(\"--image_url\", help=\"url to image\")\n",
    "    args = a.parse_args()\n",
    "\n",
    "    if args.image is None and args.image_url is None:\n",
    "        a.print_help()\n",
    "        sys.exit(1)\n",
    "\n",
    "    if args.image is not None:\n",
    "        img = Image.open(args.image)\n",
    "        preds = predict(model, img, target_size)\n",
    "        plot_preds(img, preds)\n",
    "\n",
    "    if args.image_url is not None:\n",
    "        response = requests.get(args.image_url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        preds = predict(model, img, target_size)\n",
    "        plot_preds(img, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 同上修改部分的学习和类别 和上一个是一个内容 是第二个链接的\n",
    "##  培训模型已经分享到 https://drive.google.com\n",
    "def add_new_last_layer(base_model, nb_classes):\n",
    "  \"\"\"Add last layer to the convnet\n",
    "  Args:\n",
    "    base_model: keras model excluding top\n",
    "    nb_classes: # of classes\n",
    "  Returns:\n",
    "    new keras model with last layer\n",
    "  \"\"\"\n",
    "  x = base_model.output\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  x = Dense(FC_SIZE, activation='relu')(x) \n",
    "  predictions = Dense(nb_classes, activation='softmax')(x) \n",
    "  model = Model(input=base_model.input, output=predictions)\n",
    "  return model\n",
    "\n",
    "def setup_to_transfer_learn(model, base_model):\n",
    "  \"\"\"Freeze all layers and compile the model\"\"\"\n",
    "  for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "  model.compile(optimizer='rmsprop',    \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def setup_to_finetune(model):\n",
    "   \"\"\"Freeze the bottom NB_IV3_LAYERS and retrain the remaining top \n",
    "      layers.\n",
    "   note: NB_IV3_LAYERS corresponds to the top 2 inception blocks in \n",
    "         the inceptionv3 architecture\n",
    "   Args:\n",
    "     model: keras model\n",
    "   \"\"\"\n",
    "   for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
    "      layer.trainable = False\n",
    "   for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
    "      layer.trainable = True\n",
    "   model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),   \n",
    "                 loss='categorical_crossentropy')\n",
    "\n",
    "history = model.fit_generator(\n",
    "  train_generator,\n",
    "  samples_per_epoch=nb_train_samples,\n",
    "  nb_epoch=nb_epoch,\n",
    "  validation_data=validation_generator,\n",
    "  nb_val_samples=nb_val_samples,\n",
    "  class_weight='auto')\n",
    "model.save(args.output_model_file)\n",
    "\n",
    "\n",
    "python predict.py --image dog.001.jpg --model dc.model\n",
    "python predict.py --image_url https://goo.gl/Xws7Tp --model dc.model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

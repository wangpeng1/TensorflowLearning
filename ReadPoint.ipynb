{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden layer activation functions\n",
    "\n",
    "- Main objective of using an activation function is to add a non-linearity to a layer (if we only used linear/affine projections without a non-linearity, depth would not be useful)\n",
    "- The most popular non-linearity used to be smooth functions such as \n",
    "    - **Sigmoid**: $\\sigma(x) = \\frac{1}{1 + e^{-x}} $\n",
    "    - **Hyperbolic tangent**: $\\tanh(x) = \\frac{1 - e^{-2x}}{1 + e^{-2x}}$\n",
    "- However, \"modern\" DNNs: use **rectified linear** (ReLU) functions, which are cheaper to compute (both in the forward and backward passes) and lead to good results. The ReLU is given by $\\mbox{ReLU}(x) = \\max(0, x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output activation functions\n",
    "\n",
    "The last layer of a feedforward neural network is called the output layer. It is similar to a hidden layer, but for the hidden layer we have to choose an activation function that corresponds to the type of output we intend to model:\n",
    "\n",
    "- Linear: Gaussian output distributions\n",
    "- Sigmoid: Bernoulli output distributions (binary classification)\n",
    "- Softmax: Multinoulli output distributions (multiclass classification)\n",
    "\n",
    "The **softmax**, also called normalized exponential, is a generalization of the sigmoid that converts a K-dimensional vector of arbitrary real values to a K-dimensional vector of real values in the range (0, 1) that add up to 1:\n",
    "\n",
    "$$ \\mbox{softmax}(x)_j = \\frac{e^{z_j}}{\\sum_{k=1}^{K}e^{z_k}} $$\n",
    "\n",
    "We can see the output of a softmax as $P(y = j~|~x)$.\n",
    "\n",
    "Keras does not distinguish a hidden layer from an output layer, so your output layer will be the last layer added to a `Sequential` model. Remember to set the dimensions to be the same as your target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost functions\n",
    "\n",
    "Like with the output activations, the cost function is chosen depending on the expected output distribution.\n",
    "\n",
    "- Cross-entropy: for Bernoulli and Multinoulli output distributions (binary and categorical classification)\n",
    "- Mean-squared error: for Gaussian output distributions\n",
    "\n",
    "There are other cost functions in Keras (check [the documentation](http://keras.io/objectives/) to see which ones are available).\n",
    "\n",
    "Choosing a cost function is similar to choosing an activation function: just pass it as a string or Python function using the keyword parameter `loss` to `model.compile`. All the standard cost functions have string shortcuts, so you can use `'mse', 'binary_crossentropy', 'categorical_crossentropy'` instead of having to import the functions from `keras.objectives`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Adaptive learning rate\n",
    "\n",
    "Learning rate is one of the most important hyperparameters to set for training a DNN as it has a significant impact on model performance. Also, often the choice of a single learning rate for all parameters in our model is not the best, as different parameters have different sensitivities. The adaptive learning rate approach uses separate learning rates for each parameter, and automaticallty adapts these rates during training (as it would be insane trying to find optimal values for each parameter on your own!).\n",
    "\n",
    "Keras includes several adaptive learning rate algorithms:\n",
    "\n",
    "- RMSprop\n",
    "- Adagrad\n",
    "- Adadelta\n",
    "- Adam\n",
    "- Nadam\n",
    "\n",
    "If in doubt, RMSprop and Adam with the default parameters are often a good starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU\n",
    "\n",
    "GRUs are another proposed solution for the problem of** vanishing gradients**, which use the same gating principle but are simpler than LSTMs as they only have **two gates (reset and update)** and its internal memory is the same as its hidden state, instead of using a separate cell like LSTMs. There are usually no big performance gaps between LSTM and GRU networks with the same number of parameters.\n",
    "\n",
    "GRUs are available on Keras as `keras.layers.recurrent.GRU`.\n",
    "\n",
    "## Gradient value and norm-clipping\n",
    "\n",
    "Another strategy that can mitigate the *exploding gradients* issue is gradient clipping. Gradients can be clipped either by their maximum absolute value or by the total L2 gradient norm. All optimizers in Keras support both modes of gradient clipping, by using the following keyword parameters:\n",
    "\n",
    "- `clipnorm=value` (value: float > 0): Gradients will be clipped when their L2 norm exceeds this value\n",
    "- `clipvalue=value` (value: float > 0): Gradients will be clipped when their L2 norm exceeds this value\n",
    "\n",
    "## How to connect the output of a recurrent layer to another layer\n",
    "\n",
    "We can connect the output of an RNN to the next layer in a model in two different ways:\n",
    "\n",
    "- Use all the hidden states generated by the RNN (a sequence of feature vectors) for a given sequence\n",
    "- Use only the last hidden state (one feature vector per sequence)\n",
    "\n",
    "If using the first approach, the next layer has to support processing sequences (or you can flatten the sequence as a single vector, as we have seen in the CNN section of this tutorial). To choose whether you want a recurrent layer to output a sequence or a single vector, use the keyword parameter `return_sequences`. The default for this parameter is `False`.\n",
    "\n",
    "Besides recurrent layers, Keras also supports using any layer for processing a sequence by using the `TimeDistributed` wrapper. This wrapper is equivalent to making a copy of the wrapped layer for each timestep of the sequence, with all parameters tied. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.https://github.com/Prakashvanapalli/TensorFlow 含有数学公式\n",
    "2.https://github.com/rajathkumarmp/FaceRecog-Keras 人脸识别\n",
    "3.https://github.com/chaimpollak/traffic-signs 交通信号灯\n",
    "4.https://github.com/giuseppebonaccorso/keras_deepdream 抽象画\n",
    "5.https://github.com/stratospark/food-101-keras 食物"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.add(Convolution2D(32, kernel_size=(3, 3),padding='same',input_shape=(3 , 100, 100)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, (3, 3)))\n",
    "使用same 最终变成100-3+1 =98\n",
    "convolution2d_1 (Convolution2D)  (None, 32, 100, 100)\n",
    "activation_1 (Activation)        (None, 32, 100, 100) \n",
    "convolution2d_2 (Convolution2D)  (None, 32, 98, 98) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train.shape  (148, 150, 150)\n",
    "X_train = X_train.reshape(148, 150*150)   (148, 22500)\n",
    "loss, accuracy = model.evaluate(X_test,Y_test, verbose=0)\n",
    "\n",
    "X_train shape: (50000, 32, 32, 3)\n",
    "print(X_train.shape[0], 'train samples')  50000 train samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_unit_size, init='glorot_uniform'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(p=0.2))\n",
    "model.add(Dense(nb_classes, init='glorot_uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "funition\n",
    "inputs = Input(shape=(input_unit_size,))\n",
    "x = Dense(128, activation='relu')(inputs)\n",
    "x = Dropout(0.2)(x)\n",
    "outputs = Dense(nb_classes, activation=\"softmax\")(x)\n",
    "model = Model(input=inputs, output=outputs)\n",
    "\n",
    "SVG可视化\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "\n",
    "x = range(nb_epoch)\n",
    "plt.plot(x, result.history['acc'], label=\"train acc\")\n",
    "plt.plot(x, result.history['val_acc'], label=\"val acc\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, result.history['loss'], label=\"train loss\")\n",
    "plt.plot(x, result.history['val_loss'], label=\"val loss\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model without weights\n",
    "with open('mnist_model.json', 'w') as f:\n",
    "    json.dump(model.to_json(), f)\n",
    "    \n",
    "model.save_weights('mnist_weights.h5')\n",
    "\n",
    "# load model\n",
    "mnist_model = model_from_json(json.load(open(\"mnist_model.json\")))\n",
    "\n",
    "# load wights\n",
    "mnist_model.load_weights(\"./mnist_weights.h5\")\n",
    "mnist_model.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-908b4b6eaf6b>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-908b4b6eaf6b>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    X_train shape: (60000, 1, 28, 28)\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols) \n",
    "X_train shape: (60000, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "nb_filters使用\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv, input_shape=(1, img_rows, img_cols)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"adadelta\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "中间层可视化\n",
    "get_first_layer_output = K.function([model.layers[0].input],\n",
    "                                    [model.layers[1].output])\n",
    "first_layer = get_first_layer_output([X_train[0:show_size]])[0]\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "for img_index, filters in enumerate(first_layer, start=1):\n",
    "    for filter_index, mat in enumerate(filters):\n",
    "        pos = (filter_index)*10+img_index\n",
    "        draw_digit(mat, nb_filters, show_size, pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考prodLDA 自定义层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(nb_filter, 3, 3, input_shape=(img_channels, img_rows, img_cols), border_mode=\"same\", activation=\"relu\"))\n",
    "model.add(Convolution2D(nb_filter, 3, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "model.add(Convolution2D(nb_filter, 3, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(nb_filter, 3, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "model.add(Convolution2D(nb_filter, 3, 3, border_mode=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dense(nb_classes, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "\n",
    "\n",
    "in_img = Input(shape=(img_channels, img_rows, img_cols))\n",
    "x = Convolution2D(nb_filter, 3, 3, border_mode=\"same\", activation=\"relu\")(in_img)\n",
    "for _ in range(2):\n",
    "    y = Convolution2D(nb_filter, 3, 3, border_mode=\"same\", activation=\"relu\")(x)\n",
    "    y = Convolution2D(nb_filter, 3, 3, border_mode=\"same\")(y)\n",
    "    x = merge([x, y], mode=\"sum\")\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dense(nb_classes, activation=\"softmax\")(x)\n",
    "\n",
    "\n",
    "residual = Model(input=in_img, output=x)\n",
    "\n",
    "residual.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "SVG(model_to_dot(residual, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "整个公式的演化\n",
    "TensorFlow-master/Blogposts/Backpropogation.ipynb\n",
    "TensorFlow-master/Inital_learning/ 各种py脚本\n",
    "\n",
    "traffic-signs-logistic_regression/ 也是脚本\n",
    "\n",
    "weights = {\n",
    "    'cnn_in': tf.Variable(tf.truncated_normal([filter_size_width, filter_size_height, color_channels, k_output])),\n",
    "    'cnn_out': tf.Variable(tf.random_normal([8*8*64, n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_layer, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'cnn_in': tf.Variable(tf.zeros(k_output)),\n",
    "    'cnn_out': tf.Variable(tf.random_normal([n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "引用\n",
    "# Apply Convolution\n",
    "conv_layer = tf.nn.conv2d(x, weights['cnn_in'], strides=[1, 2, 2, 1], padding='SAME')\n",
    "conv_layer = tf.nn.bias_add(conv_layer, biases['cnn_in'])\n",
    "\n",
    "\n",
    "\n",
    "img = image.load_img('dog.jpeg',target_size=(150, 150))\n",
    "x = np.asarray(img, dtype='float32')\n",
    "x = x.transpose(2, 0, 1)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "preds = model.predict(x)\n",
    "print(preds)\n",
    "\n",
    ":\n",
    "print('evaluating ...')\n",
    "score = model.evaluate(x_test, y_test, batch_size = batch_size, verbose = 1)\n",
    "print('score:', score[0])\n",
    "print('accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('music_classification.hdf5')\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "new_output = model.layers[-1].output\n",
    "feature_vec_model = Model(model.input, new_output)\n",
    "\n",
    "feature_vec_model.save('music_feature_extractor.hdf5')\n",
    "\n",
    "TensorFlow-master/Benchmarking_optimizers/experiment_mnist.ipynb 自定义model 和数组每个测试\n",
    "optimizer = [\"sgd\", \"momentum\", \"nestrov_momentum\", \"adagrad\", \"adadelta\", \"rmsprop\", \"adam\"]\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1]\n",
    "model.compile_graph(optimize = optimizer[1], learning_rate = learning_rate[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three main flavors of gradient descent are batch, stochastic, and mini-batch.\n",
    "http://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/\n",
    "Stochastic gradient descent, often abbreviated SGD, is a variation of the gradient descent algorithm that calculates the error and updates the model for each example in the training dataset.\n",
    "Upsides\n",
    "\n",
    "The frequent updates immediately give an insight into the performance of the model and the rate of improvement.\n",
    "This variant of gradient descent may be the simplest to understand and implement, especially for beginners.\n",
    "The increased model update frequency can result in faster learning on some problems.\n",
    "The noisy update process can allow the model to avoid local minima (e.g. premature convergence).\n",
    "Downsides\n",
    "\n",
    "Updating the model so frequently is more computationally expensive than other configurations of gradient descent, taking significantly longer to train models on large datasets.\n",
    "The frequent updates can result in a noisy gradient signal, which may cause the model parameters and in turn the model error to jump around (have a higher variance over training epochs).\n",
    "The noisy learning process down the error gradient can also make it hard for the algorithm to settle on an error minimum for the model.\n",
    "\n",
    "\n",
    "Batch gradient descent is a variation of the gradient descent algorithm that calculates the error for each example in the training dataset, but only updates the model after all training examples have been evaluated.\n",
    "\n",
    "\n",
    "Mini-batch gradient descent is a variation of the gradient descent algorithm that splits the training dataset into small batches that are used to calculate model error and update model coefficients.\n",
    "\n",
    "\n",
    "Upsides\n",
    "\n",
    "The model update frequency is lower than batch gradient descent which allows for a more robust convergence, avoiding local minima.\n",
    "The batched updates provide a computationally more efficient process than stochastic gradient descent.\n",
    "The batching allows both the efficiency of not having all training data in memory and algorithm implementations.\n",
    "Downsides\n",
    "\n",
    "Mini-batch requires the configuration of an additional “mini-batch size” hyperparameter for the learning algorithm.\n",
    "Error information must be accumulated across mini-batches of training examples like batch gradient descent.\n",
    "\n",
    "A good default for batch size might be 32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** convert_to_tensor**\n",
    "m2 = np.array([[1.0, 2.0], \n",
    "           [3.0, 4.0]], dtype=np.float32)\n",
    "\n",
    "m3 = tf.constant([[1.0, 2.0], \n",
    "             [3.0, 4.0]])\n",
    "print(type(m2))\n",
    "print(type(m3))\n",
    "\n",
    "<class 'numpy.ndarray'>\n",
    "<class 'tensorflow.python.framework.ops.Tensor'>\n",
    "\n",
    "t2 = tf.convert_to_tensor(m2, dtype=tf.float32)\n",
    "t3 = tf.convert_to_tensor(m3, dtype=tf.float32)\n",
    "<class 'tensorflow.python.framework.ops.Tensor'>\n",
    "<class 'tensorflow.python.framework.ops.Tensor'>\n",
    "\n",
    "TensorFlow-Book-master/ch02_basics/Concept01_defining_tensors.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import tqdm\n",
    "from sklearn import dummy, metrics, cross_validation, ensemble\n",
    "\n",
    "import keras.models as kmodels\n",
    "import keras.layers as klayers\n",
    "import keras.backend as K\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download the dataset. It's small, only about 6 MB.\n",
    "if not os.path.exists('./ml-1m'):\n",
    "    url = 'http://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_length = response.headers.get('content-length')\n",
    "    bar = tqdm.tqdm_notebook(total=int(total_length))\n",
    "    with open('./ml-1m.zip', 'wb') as f:\n",
    "        for data in response.iter_content(chunk_size=4096):\n",
    "            f.write(data)\n",
    "            bar.update(4096)\n",
    "    zip_ref = zipfile.ZipFile('./ml-1m.zip', 'r')\n",
    "    zip_ref.extractall('.')\n",
    "    zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the dataset, and do a little preprocessing,\n",
    "# mostly to set the column datatypes.\n",
    "users = pandas.read_csv('./ml-1m/users.dat', sep='::', \n",
    "                        engine='python', \n",
    "                        names=['userid', 'gender', 'age', 'occupation', 'zip']).set_index('userid')\n",
    "ratings = pandas.read_csv('./ml-1m/ratings.dat', engine='python', \n",
    "                          sep='::', names=['userid', 'movieid', 'rating', 'timestamp'])\n",
    "movies = pandas.read_csv('./ml-1m/movies.dat', engine='python',\n",
    "                         sep='::', names=['movieid', 'title', 'genre']).set_index('movieid')\n",
    "movies['genre'] = movies.genre.str.split('|')\n",
    "\n",
    "users.age = users.age.astype('category')\n",
    "users.gender = users.gender.astype('category')\n",
    "users.occupation = users.occupation.astype('category')\n",
    "ratings.movieid = ratings.movieid.astype('category')\n",
    "ratings.userid = ratings.userid.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          1193\n",
      "1           661\n",
      "2           914\n",
      "3          3408\n",
      "4          2355\n",
      "5          1197\n",
      "6          1287\n",
      "7          2804\n",
      "8           594\n",
      "9           919\n",
      "10          595\n",
      "11          938\n",
      "12         2398\n",
      "13         2918\n",
      "14         1035\n",
      "15         2791\n",
      "16         2687\n",
      "17         2018\n",
      "18         3105\n",
      "19         2797\n",
      "20         2321\n",
      "21          720\n",
      "22         1270\n",
      "23          527\n",
      "24         2340\n",
      "25           48\n",
      "26         1097\n",
      "27         1721\n",
      "28         1545\n",
      "29          745\n",
      "           ... \n",
      "1000179    2762\n",
      "1000180    1036\n",
      "1000181     508\n",
      "1000182    1041\n",
      "1000183    3735\n",
      "1000184    2791\n",
      "1000185    2794\n",
      "1000186     527\n",
      "1000187    2003\n",
      "1000188     535\n",
      "1000189    2010\n",
      "1000190    2011\n",
      "1000191    3751\n",
      "1000192    2019\n",
      "1000193     541\n",
      "1000194    1077\n",
      "1000195    1079\n",
      "1000196     549\n",
      "1000197    2020\n",
      "1000198    2021\n",
      "1000199    2022\n",
      "1000200    2028\n",
      "1000201    1080\n",
      "1000202    1089\n",
      "1000203    1090\n",
      "1000204    1091\n",
      "1000205    1094\n",
      "1000206     562\n",
      "1000207    1096\n",
      "1000208    1097\n",
      "Name: movieid, Length: 1000209, dtype: category\n",
      "Categories (3706, int64): [1, 2, 3, 4, ..., 3949, 3950, 3951, 3952]\n",
      "(1000209, 4)\n",
      "____________\n",
      "[   0    0    0 ..., 6039 6039 6039]\n",
      "____________\n",
      "[1104  639  853 ...,  548 1024 1025]\n"
     ]
    }
   ],
   "source": [
    "# Count the movies and users\n",
    "n_movies = movies.shape[0]\n",
    "n_users = users.shape[0]\n",
    "\n",
    "# Also, make vectors of all the movie ids and user ids. These are\n",
    "# pandas categorical data, so they range from 1 to n_movies and 1 to n_users, respectively.\n",
    "movieid = ratings.movieid.cat.codes.values\n",
    "userid = ratings.userid.cat.codes.values\n",
    "print (ratings.movieid)\n",
    "print (ratings.shape)\n",
    "print (\"____________\")\n",
    "print (userid)\n",
    "print (\"____________\")\n",
    "print (movieid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# And finally, set up a y variable with the rating,\n",
    "# as a one-hot encoded matrix.\n",
    "#\n",
    "# note the '- 1' for the rating. That's because ratings\n",
    "# go from 1 to 5, while the matrix columns go from 0 to 4\n",
    "\n",
    "y = np.zeros((ratings.shape[0], 5))\n",
    "y[np.arange(ratings.shape[0]), ratings.rating - 1] = 1\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userid movieid  rating\n",
      "0            1    1193       5\n",
      "1            1     661       3\n",
      "2            1     914       3\n",
      "3            1    3408       4\n",
      "4            1    2355       5\n",
      "5            1    1197       3\n",
      "6            1    1287       5\n",
      "7            1    2804       5\n",
      "8            1     594       4\n",
      "9            1     919       4\n",
      "10           1     595       5\n",
      "11           1     938       4\n",
      "12           1    2398       4\n",
      "13           1    2918       4\n",
      "14           1    1035       5\n",
      "15           1    2791       4\n",
      "16           1    2687       3\n",
      "17           1    2018       4\n",
      "18           1    3105       5\n",
      "19           1    2797       4\n",
      "20           1    2321       3\n",
      "21           1     720       3\n",
      "22           1    1270       5\n",
      "23           1     527       5\n",
      "24           1    2340       3\n",
      "25           1      48       5\n",
      "26           1    1097       4\n",
      "27           1    1721       4\n",
      "28           1    1545       4\n",
      "29           1     745       3\n",
      "...        ...     ...     ...\n",
      "1000179   6040    2762       4\n",
      "1000180   6040    1036       3\n",
      "1000181   6040     508       4\n",
      "1000182   6040    1041       4\n",
      "1000183   6040    3735       4\n",
      "1000184   6040    2791       4\n",
      "1000185   6040    2794       1\n",
      "1000186   6040     527       5\n",
      "1000187   6040    2003       1\n",
      "1000188   6040     535       4\n",
      "1000189   6040    2010       5\n",
      "1000190   6040    2011       4\n",
      "1000191   6040    3751       4\n",
      "1000192   6040    2019       5\n",
      "1000193   6040     541       4\n",
      "1000194   6040    1077       5\n",
      "1000195   6040    1079       2\n",
      "1000196   6040     549       4\n",
      "1000197   6040    2020       3\n",
      "1000198   6040    2021       3\n",
      "1000199   6040    2022       5\n",
      "1000200   6040    2028       5\n",
      "1000201   6040    1080       4\n",
      "1000202   6040    1089       4\n",
      "1000203   6040    1090       3\n",
      "1000204   6040    1091       1\n",
      "1000205   6040    1094       5\n",
      "1000206   6040     562       5\n",
      "1000207   6040    1096       4\n",
      "1000208   6040    1097       4\n",
      "\n",
      "[1000209 rows x 3 columns]\n",
      "0.870960969157\n"
     ]
    }
   ],
   "source": [
    "# Dummy classifier! Just see how well stupid can do.\n",
    "pred = dummy.DummyClassifier(strategy='prior')\n",
    "pred.fit(ratings[['userid', 'movieid']], ratings.rating)\n",
    "print (ratings[['userid', 'movieid','rating']])\n",
    "print(metrics.mean_absolute_error(ratings.rating, pred.predict(ratings[['userid', 'movieid']])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\layers.py:456: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "# Now, the deep learning classifier\n",
    "\n",
    "# First, we take the movie and vectorize it.\n",
    "# The embedding layer is normally used for sequences (think, sequences of words)\n",
    "# so we need to flatten it out.\n",
    "# The dropout layer is also important in preventing overfitting\n",
    "movie_input = keras.layers.Input(shape=[1])\n",
    "movie_vec = keras.layers.Flatten()(keras.layers.Embedding(n_movies + 1, 32)(movie_input))\n",
    "movie_vec = keras.layers.Dropout(0.5)(movie_vec)\n",
    "\n",
    "\n",
    "# Same thing for the users\n",
    "user_input = keras.layers.Input(shape=[1])\n",
    "user_vec = keras.layers.Flatten()(keras.layers.Embedding(n_users + 1, 32)(user_input))\n",
    "user_vec = keras.layers.Dropout(0.5)(user_vec)\n",
    "\n",
    "# Next, we join them all together and put them\n",
    "# through a pretty standard deep learning architecture\n",
    "input_vecs = keras.layers.merge([movie_vec, user_vec], mode='concat')\n",
    "nn = keras.layers.Dropout(0.5)(keras.layers.Dense(128, activation='relu')(input_vecs))\n",
    "nn = keras.layers.normalization.BatchNormalization()(nn)\n",
    "nn = keras.layers.Dropout(0.5)(keras.layers.Dense(128, activation='relu')(nn))\n",
    "nn = keras.layers.normalization.BatchNormalization()(nn)\n",
    "nn = keras.layers.Dense(128, activation='relu')(nn)\n",
    "\n",
    "# Finally, we pull out the result!\n",
    "result = keras.layers.Dense(5, activation='softmax')(nn)\n",
    "\n",
    "# And make a model from it that we can actually run.\n",
    "model = kmodels.Model([movie_input, user_input], result)\n",
    "model.compile('adam', 'categorical_crossentropy')\n",
    "\n",
    "# If we wanted to inspect part of the model, for example, to look\n",
    "# at the movie vectors, here's how to do it. You don't need to \n",
    "# compile these models unless you're going to train them.\n",
    "final_layer = kmodels.Model([movie_input, user_input], nn)\n",
    "movie_vec = kmodels.Model(movie_input, movie_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.]\n",
      " ..., \n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.]]\n",
      "----------\n",
      "[[ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  1.]\n",
      " ..., \n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  1.]]\n",
      "----------\n",
      "[1201 1743 2505 ...,  263 1824 1935] [1420  954 1899 ..., 2634 1110 1089] [5348 1957 4131 ..., 5642 5963  628] [1065  537 5921 ..., 5910 1973 5515]\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test sets...\n",
    "a_movieid, b_movieid, a_userid, b_userid, a_y, b_y = cross_validation.train_test_split(movieid, userid, y)\n",
    "print( a_y)\n",
    "print(\"----------\")\n",
    "print( b_y)\n",
    "print(\"----------\")\n",
    "print(a_movieid, b_movieid, a_userid, b_userid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7980268183145174"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And of _course_ we need to make sure we're improving, so we find the MAE before\n",
    "# training at all.\n",
    "metrics.mean_absolute_error(np.argmax(b_y, 1)+1, np.argmax(model.predict([b_movieid, b_userid]), 1)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750156 samples, validate on 250053 samples\n",
      "Epoch 1/20\n",
      "  1024/750156 [..............................] - ETA: 506732s - loss: 1.83 - ETA: 513437s - loss: 1.80 - ETA: 511306s - loss: 1.90 - ETA: 514319s - loss: 1.87 - ETA: 514609s - loss: 1.87 - ETA: 512198s - loss: 1.88 - ETA: 511048s - loss: 1.85 - ETA: 510101s - loss: 1.83 - ETA: 508993s - loss: 1.81 - ETA: 508976s - loss: 1.81 - ETA: 508880s - loss: 1.78 - ETA: 508983s - loss: 1.77 - ETA: 509785s - loss: 1.76 - ETA: 508820s - loss: 1.76 - ETA: 508010s - loss: 1.76 - ETA: 507895s - loss: 1.76 - ETA: 507185s - loss: 1.76 - ETA: 506684s - loss: 1.75 - ETA: 506646s - loss: 1.74 - ETA: 506202s - loss: 1.73 - ETA: 505756s - loss: 1.73 - ETA: 507130s - loss: 1.72 - ETA: 506767s - loss: 1.72 - ETA: 506441s - loss: 1.71 - ETA: 506383s - loss: 1.71 - ETA: 505957s - loss: 1.71 - ETA: 505781s - loss: 1.70 - ETA: 505666s - loss: 1.69 - ETA: 505515s - loss: 1.69 - ETA: 505502s - loss: 1.68 - ETA: 505652s - loss: 1.68 - ETA: 505492s - loss: 1.6781"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    history = model.fit([a_movieid, a_userid], a_y, \n",
    "                         nb_epoch=20, \n",
    "                         validation_data=([b_movieid, b_userid], b_y))\n",
    "    plot(history.history['loss'])\n",
    "    plot(history.history['val_loss'])\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67782430124813542"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the number that matters. It's the held out \n",
    "# test set score. Note the + 1, because np.argmax will\n",
    "# go from 0 to 4, while our ratings go 1 to 5.\n",
    "metrics.mean_absolute_error(\n",
    "    np.argmax(b_y, 1)+1, \n",
    "    np.argmax(model.predict([b_movieid, b_userid]), 1)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65481579831395065"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For comparison's sake, here's the score on the training set.\n",
    "metrics.mean_absolute_error(\n",
    "    np.argmax(a_y, 1)+1, \n",
    "    np.argmax(model.predict([a_movieid, a_userid]), 1)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
